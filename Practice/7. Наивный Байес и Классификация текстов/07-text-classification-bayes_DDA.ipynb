{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nB0aFMdYbe3q"
   },
   "source": [
    "# 7. –ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å –∏ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤\n",
    "\n",
    "> –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤  \n",
    "> –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞\n",
    "\n",
    "1. –°–∫–∞—á–∞–π—Ç–µ —ç—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –∫ —Å–µ–±–µ.\n",
    "2. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏, –æ—Ç–≤–µ—á–∞—è –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã. –¢–∞–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–¥! (–µ—Å–ª–∏ –Ω–µ —Å–∫–∞–∑–∞–Ω–æ –æ–±—Ä–∞—Ç–Ω–æ–µ)\n",
    "3. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–≤–æ—ë–º –≥–∏—Ç—Ö–∞–± —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.\n",
    "\n",
    "### –ü–æ–ª–µ–∑–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞\n",
    "\n",
    "- [Naive Bayes and Text Classification](https://sebastianraschka.com/Articles/2014_naive_bayes_1.html)\n",
    "- [ODS - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è](https://habrahabr.ru/company/ods/blog/322534/)\n",
    "- [–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä](http://www.machinelearning.ru/wiki/index.php?title=%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80)\n",
    "- [–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–æ —Å–ø–∞–º/–Ω–µ —Å–ø–∞–º](https://habrahabr.ru/post/252265/)\n",
    "\n",
    "–ï—Å–ª–∏ –≤–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å –∑–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤, —Ç–æ –≤–æ—Ç –ø–æ–¥–±–æ—Ä–æ—á–∫–∞:\n",
    "\n",
    "- [–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Gensim](https://radimrehurek.com/gensim/)\n",
    "- [–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ nltk](http://www.nltk.org/)\n",
    "- [–õ–µ–∫—Ü–∏—è –ø—Ä–æ word2vec üî•](https://www.youtube.com/watch?v=oBb9aFmp0Hs)\n",
    "- [–õ–µ–∫—Ü–∏—è –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ üî•](https://www.youtube.com/watch?v=hiDBnEyoZS4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dijVKK51be3y"
   },
   "source": [
    "## –ù–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "\n",
    "–ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –µ–≥–æ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º/–Ω–µ —Å–ø–∞–º. –í —ç—Ç–æ—Ç —Ä–∞–∑ –≤—ã –±—É–¥–µ—Ç–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å [–Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html). –ü–æ–ø—Ä–æ–±—É–µ—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã  –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vuwyg7qbe30",
    "outputId": "660a5e9b-30b1-4f07-8f1c-b803736e776d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CffeqYRBbe4I"
   },
   "source": [
    "### 2.1 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (2 –±–∞–ª–ª–∞)\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ 4 –∫–ª–∞—Å—Å–∞ —Ç–µ–∫—Å—Ç–æ–≤: `'alt.atheism', 'sci.space', 'talk.religion.misc', 'comp.graphics'`.\n",
    "\n",
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —ç—Ç–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A070kEpUbe4L"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism','comp.graphics',\\\n",
    "               'sci.space','talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='all',\n",
    "    categories=categories, remove=('headers', 'footers', 'quotes'))#, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TomTxX1Mbe4c"
   },
   "source": [
    "–í—ã–≤–µ–¥–∏—Ç–µ –ø–æ 1 —Ç–µ–∫—Å—Ç—É –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(data):\n",
    "\n",
    "    df = pd.DataFrame([data.data, data.target.tolist()]).T\n",
    "    df.columns = ['text', 'target']\n",
    "\n",
    "    targets = pd.DataFrame(data.target_names)\n",
    "    targets.columns=['category']\n",
    "\n",
    "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My point is that you set up your views as the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n]The \"corrupted over and over\" theory is pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n\\nBut, you wouldn't know what red *was*, and...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\n\\nWell I agree with you in the sense that th...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\n\\nSpecifically, which changes are you talkin...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text target     category\n",
       "0   My point is that you set up your views as the ...      0  alt.atheism\n",
       "9    \\n]The \"corrupted over and over\" theory is pr...      0  alt.atheism\n",
       "14  \\n\\nBut, you wouldn't know what red *was*, and...      0  alt.atheism\n",
       "26  \\n\\nWell I agree with you in the sense that th...      0  alt.atheism\n",
       "27  \\n\\nSpecifically, which changes are you talkin...      0  alt.atheism"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category(0): alt.atheism\n",
      "\n",
      "My point is that you set up your views as the only way to believe.  Saying \n",
      "that all eveil in this world is caused by atheism is ridiculous and \n",
      "counterproductive to dialogue in this newsgroups.  I see in your posts a \n",
      "spirit of condemnation of the atheists in this newsgroup bacause they don'\n",
      "t believe exactly as you do.  If you're here to try to convert the atheists \n",
      "here, you're failing miserably.  Who wants to be in position of constantly \n",
      "defending themselves agaist insulting attacks, like you seem to like to do?!\n",
      "I'm sorry you're so blind that you didn't get the messgae in the quote, \n",
      "everyone else has seemed to.\n",
      "-----------------\n",
      "Category(1): comp.graphics\n",
      "\n",
      "\n",
      "By '8 grey level images' you mean 8 items of 1bit images?\n",
      "It does work(!), but it doesn't work if you have more than 1bit\n",
      "in your screen and if the screen intensity is non-linear.\n",
      "\n",
      "With 2 bit per pixel; there could be 1*c_1 + 4*c_2 timing,\n",
      "this gives 16 levels, but they are linear if screen intensity is\n",
      "linear.\n",
      "With 1*c_1 + 2*c_2 it works, but we have to find the best\n",
      "compinations -- there's 10 levels, but 16 choises; best 10 must be\n",
      "chosen. Different compinations for the same level, varies a bit, but\n",
      "the levels keeps their order.\n",
      "\n",
      "Readers should verify what I wrote... :-)\n",
      "-----------------\n",
      "Category(3): talk.religion.misc\n",
      "\n",
      "I responded to Jim's other articles today, but I see that I neglected\n",
      "to respond to this one.  I wouldn't want him to think me a hypocrite\n",
      "for not responding to *every* stupid article on t.r.m.\n",
      "\n",
      "[dictionary definitions of \"not\" \"disagree\" and \"agree\" deleted]\n",
      "\n",
      "Oh, but I'm weary of trying to wade through Jim's repertoire of \n",
      "red herrings and smoke screens.\n",
      "\n",
      "Let's see what we get when we run all four articles posted by Jim today\n",
      "through the 'discord' filter (a Markov chain program that Steve Lamont\n",
      "was kind enough to send me):\n",
      "\n",
      "\tTaking action? A white geese be held\n",
      "\tas an accomplice to be held as\n",
      "\ta decision upon the door\n",
      "\tA black and white goose waddles past\n",
      "\tthe eyes of the door. \n",
      "\tHits it with the confidence interval for \n",
      "\tthat individual is held responsible \n",
      "\tfor that, that individual \n",
      "\tmay be held as a \n",
      "\tgetaway car may be held \n",
      "\tas an uncountably large number \n",
      "\tof the driver of something \n",
      "\tand agree.\n",
      "\n",
      "\tA black goose \n",
      "\twaddles past the person imprisoned?\n",
      "\n",
      "\tWhite goose waddles past the \n",
      "\tconfidence interval for the population \n",
      "\tof geese be axed, \n",
      "\tfine.\n",
      "\tAnd white goose \n",
      "\twaddles past the door.\n",
      "\n",
      "Does running Jim's articles through 'discord' make them more\n",
      "coherent?  Less coherent?\n",
      "\n",
      "Or has 'discord' turned Jim's articles into an angst-ridden poem\n",
      "about making choices in a world filled with uncertainty, yet being\n",
      "held responsible for the choices we make?  Do the geese symbolize\n",
      "an inner frustration with ambiguity, a desire that everything be\n",
      "black and white, with no shades of gray?  Does the \"getaway car\"\n",
      "tell us that to try to renounce the existential nature of our\n",
      "being is not to \"get away\" from responsibility for our actions,\n",
      "but rather to take the role of the passive accomplice, the\n",
      "\"driver\" of the getaway car, as it were?  Does the juxtaposition\n",
      "of man and machine, car and driver, reveal a subtext: an internal\n",
      "conflict between determinism and moral responsibility?\n",
      "\n",
      "Or am I reading too much into a collaboration between Jim and\n",
      "a random number generator?\n",
      "-----------------\n",
      "Category(2): sci.space\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tThey did the rollout already??!?  I am going to have to pay more\n",
      "attention to the news.  Are any of the gifs headed for wuarchive??\n",
      " \n",
      "\n",
      "Patrick\n",
      "\n",
      "\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for cat in df.category.unique():\n",
    "    row = df[df['category']==cat].head(1)\n",
    "    print('Category({}): {}\\n'.format(row['target'][:1].values[0],cat))  \n",
    "    print(row['text'][:1].values[0])\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oh0qM926be4j"
   },
   "outputs": [],
   "source": [
    "#for i in range(0,4):\n",
    "#    print('Category: {}\\n'.format(four_train.target_names[i]))\n",
    "#    print(\"\\n\".join(four_train.data[i].split(\"\\n\")[:3]))\n",
    "#    print('-----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JygPRk9vbe40"
   },
   "source": [
    "### 2.2 –ú–µ—à–æ–∫ —Å–ª–æ–≤ (6 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "–ù–∞—á–Ω–µ–º —Å —Å–∞–º–æ–≥–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–ø–æ—Å–æ–±–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤: –æ–±—ã—á–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–π —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –µ–≥–æ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∞–Ω–≥–ª–∏—Å–∫–∏–µ —Å—Ç–æ–ø —Å–ª–æ–≤–∞.\n",
    "\n",
    "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –≤—ã–≤–µ–¥–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è. (1 –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞! –£ –≤–∞—Å –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å—Å—è –º–∞—Ç—Ä–∏—Ü—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏-—Å–ª–æ–≤–∞–º–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARVAfHodbe49"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].astype('int')\n",
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vector = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ:  33529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3387, 33529)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ: \", len(vectorizer.vocabulary_))\n",
    "X_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2RUrm1Cbe5K"
   },
   "source": [
    "–ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∞–∫—Ç–æ—Ä –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∏—Ñ–∫–∞—Ü–∏–∏ [sklearn.naive_bayes.MultinomialNB]().\n",
    "\n",
    "- –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ 5 —Ñ–æ–ª–¥–∞—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ `accuracy`.\n",
    "- –æ–±—É—á–∏—Ç–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, \n",
    "- –Ω–∞—Ä–∏—Å—É–π—Ç–µ –∫—Ä–∞—Å–∏–≤—É—é confusion –º–∞—Ç—Ä–∏—Ü—É, (—Å –∏–º–µ–Ω–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤, –∞ –Ω–µ –∏–Ω–¥–µ–∫—Å–∞–º–∏ –ø–æ –æ—Å—è–º)\n",
    "- –≤—ã–≤–µ–¥–∏—Ç–µ –æ—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (—Å –∏–º–µ–Ω–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤, –∞ –Ω–µ –∏–Ω–¥–µ–∫—Å–∞–º–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKtNMOUybe5s"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split,GridSearchCV, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 197 ms, sys: 7.1 ms, total: 204 ms\n",
      "Wall time: 456 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [1, 2, 3, 4, 5, 6, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "            \"alpha\": [1,2,3,4,5,6,10], \n",
    "         }\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search = GridSearchCV(MultinomialNB(), params, cv=cv, verbose=2,n_jobs=-1, scoring='accuracy')                    \n",
    "\n",
    "%time search.fit(X_vector, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: score=0.8190106447410272, params={'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"BEST: score={}, params={}\".format(search.best_score_, search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vector, y, random_state=42, test_size=0.6, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(X_train, np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[389   8  27  56]\n",
      " [ 19 525  35   5]\n",
      " [ 30  35 519   8]\n",
      " [154   9  28 186]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       480\n",
      "           1       0.91      0.90      0.90       584\n",
      "           2       0.85      0.88      0.86       592\n",
      "           3       0.73      0.49      0.59       377\n",
      "\n",
      "    accuracy                           0.80      2033\n",
      "   macro avg       0.79      0.77      0.77      2033\n",
      "weighted avg       0.80      0.80      0.79      2033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaMYax0fbe55"
   },
   "outputs": [],
   "source": [
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –¢–û–ü 10 –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤–∞ –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n",
    "\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: [%s]\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vec, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lg5gSNjNbe6E"
   },
   "source": [
    "### 2.3 [Tf-IDF](https://ru.wikipedia.org/wiki/TF-IDF) (6 –±–∞–ª–ª–æ–≤) \n",
    "\n",
    "–ú–µ—à–æ–∫ —Å–ª–æ–≤ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç \"–≤–µ—Å–∞\" —Å–ª–æ–≤, –æ–Ω –ø—Ä–æ—Å—Ç–æ —Å–º–æ—Ç—Ä–∏—Ç –∏—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç. –í–µ—Ä–æ—è—Ç–Ω–æ, –±—ã–ª–æ –±—ã –ø–æ–ª–µ–∑–Ω–æ –≤–∑–≤–µ—Å–∏—Ç—å –∫–∞–∫–∏–º-—Ç–æ –æ–±—Ä–∞–æ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ. –î–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ, –µ—Å–ª–∏ —Å–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤–æ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, —Ç–æ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –µ–≥–æ –≤–µ—Å –Ω–µ–±–æ–ª—å—à–æ–π. –ê –µ—Å–ª–∏ —Ä–µ–¥–∫–æ–µ —Å–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, —Ç–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ–Ω–æ –∫–∞–∫–æ–µ-—Ç–æ —É–∑–∫–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ.\n",
    "\n",
    "–û–¥–∏–Ω –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤ –≤–∑–≤–µ—Å–∏—Ç—å —Å–ª–æ–≤–∞ - —ç—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ä—É tf-idf, –≥–¥–µ:\n",
    "\n",
    "**TF - term frequency** - —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏\n",
    "\n",
    "$$\\LARGE \\mathrm{tf}(t,d) = \\frac{n_t}{\\sum_k n_k}$$\n",
    "\n",
    "**IDF - inverse document frequency***¬†‚Äî –æ–±—Ä–∞—Ç–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ - —É–º–µ–Ω—å—à–∞–µ—Ç –≤–µ—Å —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ–º—ã—Ö —Å–ª–æ–≤\n",
    "\n",
    "$$\\LARGE \\mathrm{idf}(t, D) =  \\log \\frac{|D|}{|\\{\\,d_i \\in D \\mid t \\in d_{i}\\, \\}|}$$\n",
    "\n",
    "$D$ - —á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ\n",
    "\n",
    "$|\\{\\,d_i \\in D \\mid t \\in d_{i}\\, \\}|$ - —á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ${\\displaystyle D}$ , –≤ –∫–æ—Ç–æ—Ä—ã—Ö –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è ${\\displaystyle t}$  (–∫–æ–≥–¥–∞ ${\\displaystyle n_{t}\\neq 0}$ ).\n",
    "\n",
    "**TF-IDF**\n",
    "\n",
    "$$\\LARGE \\operatorname{tf-idf}(t,d,D) = \\operatorname{tf}(t,d) \\times \\operatorname{idf}(t, D)$$\n",
    "\n",
    "\n",
    "–î–ª—è –Ω–µ–≥–æ –µ—Å—Ç—å –∫–ª–∞—Å—Å [sklearn.feature_extraction.text.TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0olGBbu8be6J"
   },
   "source": [
    "- –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ 5 —Ñ–æ–ª–¥–∞—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ `accuracy`.\n",
    "- –æ–±—É—á–∏—Ç–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, \n",
    "- –Ω–∞—Ä–∏—Å—É–π—Ç–µ –∫—Ä–∞—Å–∏–≤—É—é confusion –º–∞—Ç—Ä–∏—Ü—É, (—Å –∏–º–µ–Ω–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤, –∞ –Ω–µ –∏–Ω–¥–µ–∫—Å–∞–º–∏ –ø–æ –æ—Å—è–º)\n",
    "- –≤—ã–≤–µ–¥–∏—Ç–µ –æ—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (—Å –∏–º–µ–Ω–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤, –∞ –Ω–µ –∏–Ω–¥–µ–∫—Å–∞–º–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNZ6Tx91be6M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APKo4A3Rbe6c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ey68nUKbe6o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-al2n9Xbe6u"
   },
   "outputs": [],
   "source": [
    "show_top10(clf, vec, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2S_uHfDbe6z"
   },
   "source": [
    "### 2.4 –í —á—ë–º –ø—Ä–æ–±–ª–µ–º–∞? (7 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "–ö–∞–∫ –≤—ã –∑–∞–º–µ—Ç–∏–ª–∏, –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ–º–Ω–æ–≥–æ —É–ª—É—á—à–∏–ª–æ—Å—å. –ö–∞–∫ –≤—ã –¥—É–º–∞–µ—Ç–µ –ø–æ—á–µ–º—É —É –Ω–∞—Å –¥–æ —Å–∏—Ö –ø–æ—Ä –µ—Å—Ç—å –æ—à–∏–±–∫–∏? –í —á—ë–º –ø—Ä–æ–±–ª–µ–º–∞? –û–ø–∏—Ä–∞–π—Ç–µ—Å—å –Ω–∞ –≤—ã–≤–æ–¥ —Ç–æ–ø–∞ 10 –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤, confusion matrix –∏ —Ä–µ–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "\n",
    "**–ó–∞–¥–∞–Ω–∏–µ**: –ù–∞–ø–∏—à–∏—Ç–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my0w7i9Lbe63"
   },
   "source": [
    "–û—Ç–≤–µ—Ç: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXN0OyhQbe64"
   },
   "source": [
    "![](https://i.imgur.com/3D5pgrk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OclFB5x1be65"
   },
   "source": [
    "–ú–æ–∂–Ω–æ –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤—Ç—å n-–≥—Ä–∞–º–º—ã, —Ç–æ –µ—Å—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞, –Ω–æ –∏ –ø–∞—Ä—ã, —Ç—Ä–æ–π–∫–∏. –î–ª—è —ç—Ç–æ–≥–æ —É –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä–∞ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä `ngram_range`, –Ω–æ –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ò—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å  `max_features`. –ï—â—ë –º–æ–∂–Ω–æ –∫–æ–ø–∞—Ç—å –≤ —Å—Ç–æ—Ä–æ–Ω—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤: –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Å—Ç–µ–º–º–∏–Ω–≥, —á—Ç–æ–±—ã —É–±–∏—Ä–∞—Ç—å –æ–∫–æ–Ω—á–∞–Ω–∏—è, –Ω–æ —ç—Ç–æ –æ–±—á–Ω–æ –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
    "\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–π—Ç–∏ —Å–æ–≤—Å–µ–º –≤ –¥—Ä—É–≥—É—é —Å—Ç–æ—Ä–æ–Ω—É –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å word-2-vec —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, —Ç–æ–≥–¥–∞ –±—ã —É –Ω–∞—Å —Å–ª–æ–≤–∞ –Ω–∞—á–∞–ª \"–æ–±—Ä–µ—Ç–∞—Ç—å\" —Å–º—ã—Å–ª. –ù–æ —ç—Ç–æ –≤–æ–≤—Å–µ–º –¥—Ä—É–≥–∞—è –∏—Å—Ç–æ—Ä–∏—è."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "07-text-classification-bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
